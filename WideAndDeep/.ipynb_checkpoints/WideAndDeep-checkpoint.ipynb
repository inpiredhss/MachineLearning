{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from os import path, listdir\n",
    "from sklearn.datasets import load_svmlight_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.contrib import layers\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n",
      "['D:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow', 'D:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\python\\\\estimator\\\\api']\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(tf.__path__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2）数据准备\n",
    "# 定义输入样本格式\n",
    "\n",
    "_CSV_COLUMNS = [\n",
    "     'age', 'workclass', 'fnlwgt', 'education', 'education_num',\n",
    "     'marital_status', 'occupation', 'relationship', 'race', 'gender',\n",
    "     'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "     'income_bracket'\n",
    "]\n",
    "_CSV_COLUMN_DEFAULTS = [[0], [''], [0], [''], [0], [''], [''], [''], [''], [''],\n",
    "                        [0], [0], [0], [''], ['']]\n",
    "_NUM_EXAMPLES = {\n",
    "    'train': 32561,\n",
    "    'validation': 16281,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Builds a set of wide and deep feature columns.\"\"\"\n",
    "def build_model_columns():\n",
    "    # 1. 特征处理，包括：连续特征、离散特征、转换特征、交叉特征等\n",
    "\n",
    "    # 连续特征 （其中在Wide和Deep组件都会用到）\n",
    "    age = tf.feature_column.numeric_column('age')\n",
    "    education_num = tf.feature_column.numeric_column('education_num')\n",
    "    capital_gain = tf.feature_column.numeric_column('capital_gain')\n",
    "    capital_loss = tf.feature_column.numeric_column('capital_loss')\n",
    "    hours_per_week = tf.feature_column.numeric_column('hours_per_week')\n",
    "\n",
    "    # 离散特征\n",
    "    education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'education', [\n",
    "            'Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college',\n",
    "            'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school',\n",
    "            '5th-6th', '10th', '1st-4th', 'Preschool', '12th'])\n",
    "\n",
    "    marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'marital_status', [\n",
    "            'Married-civ-spouse', 'Divorced', 'Married-spouse-absent',\n",
    "            'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'])\n",
    "\n",
    "    relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'relationship', [\n",
    "            'Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried',\n",
    "            'Other-relative'])\n",
    "\n",
    "    workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'workclass', [\n",
    "            'Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov',\n",
    "            'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'])\n",
    "\n",
    "    # 离散hash bucket特征\n",
    "    occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "        'occupation', hash_bucket_size=1000\n",
    "    )\n",
    "\n",
    "    # 特征Transformations\n",
    "    age_buckets = tf.feature_column.bucketized_column(\n",
    "        age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65]\n",
    "    )\n",
    "    print(\"age_buckets:\",age_buckets)\n",
    "\n",
    "    # 2. 设定Wide层特征\n",
    "    \"\"\"\n",
    "    Wide部分使用了规范化后的连续特征、离散特征、交叉特征\n",
    "    \"\"\"\n",
    "    # 基本特征列\n",
    "    base_columns = [\n",
    "        # 全是离散特征\n",
    "        education, marital_status, relationship, workclass, occupation,\n",
    "        age_buckets,\n",
    "    ]\n",
    "\n",
    "    # 交叉特征列\n",
    "    crossed_columns = [\n",
    "        tf.feature_column.crossed_column(\n",
    "            ['education', 'occupation'], hash_bucket_size=1000),\n",
    "        tf.feature_column.crossed_column(\n",
    "            [age_buckets, 'education', 'occupation'], hash_bucket_size=1000\n",
    "        )\n",
    "    ]\n",
    "    print(\"crossed_columns:\",crossed_columns)\n",
    "\n",
    "    # wide特征列\n",
    "    wide_columns = base_columns + crossed_columns\n",
    "\n",
    "    # 3. 设定Deep层特征\n",
    "    \"\"\"\n",
    "    Deep层主要针对离散特征进行处理，其中处理方式有：\n",
    "    1. Sparse Features -> Embedding vector -> 串联(连续特征)，其中Embedding Values随机初始化。\n",
    "    2. 另外一种处理离散特征的方法是：one-hot和multi-hot representation. 此方法适用于低维度特征，其中embedding是通用的做法\n",
    "    其中：采用embedding_column(embedding)和indicator_column(multi-hot)API\n",
    "    \"\"\"\n",
    "    # deep特征列\n",
    "    deep_columns = [\n",
    "        age,\n",
    "        education_num,\n",
    "        capital_gain,\n",
    "        capital_loss,\n",
    "        hours_per_week,\n",
    "        tf.feature_column.indicator_column(workclass),\n",
    "        tf.feature_column.indicator_column(education),\n",
    "        tf.feature_column.indicator_column(marital_status),\n",
    "        tf.feature_column.indicator_column(relationship),\n",
    "\n",
    "        # embedding特征\n",
    "        tf.feature_column.embedding_column(occupation, dimension=8)\n",
    "    ]\n",
    "    print(\"wide_columns:\",wide_columns)\n",
    "    print(\"deep_columns\",deep_columns)\n",
    "    return wide_columns, deep_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimator Input\n",
    "# 定义输入\n",
    "def input_fn(data_file, num_epochs, shuffle, batch_size):\n",
    "    \"\"\"为Estimator创建一个input function\"\"\"\n",
    "    assert tf.gfile.Exists(data_file), \"{0} not found.\".format(data_file)\n",
    "    def parse_csv(line):\n",
    "        print(\"Parsing\", data_file)\n",
    "        # tf.decode_csv会把csv文件转换成Tensor。其中record_defaults用于指明每一列的缺失值用什么填充。\n",
    "        columns = tf.decode_csv(line, record_defaults=_CSV_COLUMN_DEFAULTS)\n",
    "        features = dict(zip(_CSV_COLUMNS, columns))\n",
    "        labels = features.pop('income_bracket')\n",
    "        # tf.equal(x, y) 返回一个bool类型Tensor， 表示x == y, element-wise\n",
    "        return features, tf.equal(labels, '>50K') \n",
    "    dataset = tf.data.TextLineDataset(data_file).map(parse_csv, num_parallel_calls=5)\n",
    "    dataset = dataset.repeat(num_epochs)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    print(\"dataset\",dataset)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    print(\"iterator\",iterator)\n",
    "    batch_features, batch_labels = iterator.get_next()\n",
    "    return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tf.decode_csv会把csv文件转换成Tensor。其中record_defaults用于指明每一列的缺失值用什么填充。\n",
    "- tf.equal(x, y) 返回一个bool类型Tensor， 表示x == y, element-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3）模型准备\n",
    "\n",
    "# Wide & Deep Model\n",
    "def build_estimator(model_dir, model_type):\n",
    "    \"\"\"Build an estimator appropriate for the given model type.\"\"\"\n",
    "    wide_columns, deep_columns = build_model_columns()\n",
    "    hidden_units = [100, 50]\n",
    "\n",
    "    # Create a tf.estimator.RunConfig to ensure the model is run on CPU, which\n",
    "    # trains faster than GPU for this model.\n",
    "    run_config = tf.estimator.RunConfig().replace(\n",
    "      session_config=tf.ConfigProto(device_count={'GPU': 0}))\n",
    "\n",
    "    if model_type == 'wide':\n",
    "        return tf.estimator.LinearClassifier(\n",
    "          model_dir=model_dir,\n",
    "          feature_columns=wide_columns,\n",
    "          config=run_config)\n",
    "    elif model_type == 'deep':\n",
    "        return tf.estimator.DNNClassifier(\n",
    "          model_dir=model_dir,\n",
    "          feature_columns=deep_columns,\n",
    "          hidden_units=hidden_units,\n",
    "          config=run_config)\n",
    "    else:\n",
    "        return tf.estimator.DNNLinearCombinedClassifier(\n",
    "          model_dir=model_dir,\n",
    "          linear_feature_columns=wide_columns,\n",
    "          dnn_feature_columns=deep_columns,\n",
    "          dnn_hidden_units=hidden_units,\n",
    "          config=run_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hidden_units = [100, 50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_buckets: _BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65))\n",
      "crossed_columns: [_CrossedColumn(keys=('education', 'occupation'), hash_bucket_size=1000, hash_key=None), _CrossedColumn(keys=(_BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), 'education', 'occupation'), hash_bucket_size=1000, hash_key=None)]\n",
      "wide_columns: [_VocabularyListCategoricalColumn(key='education', vocabulary_list=('Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college', 'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school', '5th-6th', '10th', '1st-4th', 'Preschool', '12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=('Married-civ-spouse', 'Divorced', 'Married-spouse-absent', 'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _VocabularyListCategoricalColumn(key='relationship', vocabulary_list=('Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _VocabularyListCategoricalColumn(key='workclass', vocabulary_list=('Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov', 'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0), _HashedCategoricalColumn(key='occupation', hash_bucket_size=1000, dtype=tf.string), _BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), _CrossedColumn(keys=('education', 'occupation'), hash_bucket_size=1000, hash_key=None), _CrossedColumn(keys=(_BucketizedColumn(source_column=_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(18, 25, 30, 35, 40, 45, 50, 55, 60, 65)), 'education', 'occupation'), hash_bucket_size=1000, hash_key=None)]\n",
      "deep_columns [_NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='education_num', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='capital_gain', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='capital_loss', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _NumericColumn(key='hours_per_week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='workclass', vocabulary_list=('Self-emp-not-inc', 'Private', 'State-gov', 'Federal-gov', 'Local-gov', '?', 'Self-emp-inc', 'Without-pay', 'Never-worked'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='education', vocabulary_list=('Bachelors', 'HS-grad', '11th', 'Masters', '9th', 'Some-college', 'Assoc-acdm', 'Assoc-voc', '7th-8th', 'Doctorate', 'Prof-school', '5th-6th', '10th', '1st-4th', 'Preschool', '12th'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='marital_status', vocabulary_list=('Married-civ-spouse', 'Divorced', 'Married-spouse-absent', 'Never-married', 'Separated', 'Married-AF-spouse', 'Widowed'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), _IndicatorColumn(categorical_column=_VocabularyListCategoricalColumn(key='relationship', vocabulary_list=('Husband', 'Not-in-family', 'Wife', 'Own-child', 'Unmarried', 'Other-relative'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), _EmbeddingColumn(categorical_column=_HashedCategoricalColumn(key='occupation', hash_bucket_size=1000, dtype=tf.string), dimension=8, combiner='mean', layer_creator=<function embedding_column.<locals>._creator at 0x00000167A77CD950>, ckpt_to_load_from=None, tensor_name_in_ckpt=None, max_norm=None, trainable=True)]\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/data/model/wide_deep', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': device_count {\n",
      "  key: \"GPU\"\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000167A77DC2E8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# 模型路径\n",
    "model_type = 'widedeep'\n",
    "model_dir = '/data/model/wide_deep'\n",
    "\n",
    "# Wide & Deep 联合模型\n",
    "model = build_estimator(model_dir, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./data/adult.data\n",
      "dataset <BatchDataset shapes: ({age: (?,), workclass: (?,), fnlwgt: (?,), education: (?,), education_num: (?,), marital_status: (?,), occupation: (?,), relationship: (?,), race: (?,), gender: (?,), capital_gain: (?,), capital_loss: (?,), hours_per_week: (?,), native_country: (?,)}, (?,)), types: ({age: tf.int32, workclass: tf.string, fnlwgt: tf.int32, education: tf.string, education_num: tf.int32, marital_status: tf.string, occupation: tf.string, relationship: tf.string, race: tf.string, gender: tf.string, capital_gain: tf.int32, capital_loss: tf.int32, hours_per_week: tf.int32, native_country: tf.string}, tf.bool)>\n",
      "iterator <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x00000167A92694E0>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data/model/wide_deep\\model.ckpt-13\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 13 into /data/model/wide_deep\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.012358409, step = 14\n",
      "INFO:tensorflow:Saving checkpoints for 19 into /data/model/wide_deep\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0046499795.\n",
      "Parsing ./data/adult.test\n",
      "dataset <BatchDataset shapes: ({age: (?,), workclass: (?,), fnlwgt: (?,), education: (?,), education_num: (?,), marital_status: (?,), occupation: (?,), relationship: (?,), race: (?,), gender: (?,), capital_gain: (?,), capital_loss: (?,), hours_per_week: (?,), native_country: (?,)}, (?,)), types: ({age: tf.int32, workclass: tf.string, fnlwgt: tf.int32, education: tf.string, education_num: tf.int32, marital_status: tf.string, occupation: tf.string, relationship: tf.string, race: tf.string, gender: tf.string, capital_gain: tf.int32, capital_loss: tf.int32, hours_per_week: tf.int32, native_country: tf.string}, tf.bool)>\n",
      "iterator <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x00000167ADAE5E48>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-02-05:49:47\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data/model/wide_deep\\model.ckpt-19\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-02-05:49:48\n",
      "INFO:tensorflow:Saving dict for global step 19: accuracy = 1.0, accuracy_baseline = 1.0, auc = 0.9999999, auc_precision_recall = 0.0, average_loss = 0.0021433097, global_step = 19, label/mean = 0.0, loss = 0.010716548, precision = 0.0, prediction/mean = 0.0021222052, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 19: /data/model/wide_deep\\model.ckpt-19\n",
      "Results at epoch 3\n",
      "------------------------------\n",
      "accuracy            : 1.0000\n",
      "accuracy_baseline   : 1.0000\n",
      "auc                 : 1.0000\n",
      "auc_precision_recall: 0.0000\n",
      "average_loss        : 0.0021\n",
      "global_step         : 19.0000\n",
      "label/mean          : 0.0000\n",
      "loss                : 0.0107\n",
      "precision           : 0.0000\n",
      "prediction/mean     : 0.0021\n",
      "recall              : 0.0000\n",
      "Parsing ./data/adult.data\n",
      "dataset <BatchDataset shapes: ({age: (?,), workclass: (?,), fnlwgt: (?,), education: (?,), education_num: (?,), marital_status: (?,), occupation: (?,), relationship: (?,), race: (?,), gender: (?,), capital_gain: (?,), capital_loss: (?,), hours_per_week: (?,), native_country: (?,)}, (?,)), types: ({age: tf.int32, workclass: tf.string, fnlwgt: tf.int32, education: tf.string, education_num: tf.int32, marital_status: tf.string, occupation: tf.string, relationship: tf.string, race: tf.string, gender: tf.string, capital_gain: tf.int32, capital_loss: tf.int32, hours_per_week: tf.int32, native_country: tf.string}, tf.bool)>\n",
      "iterator <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x00000167AC79EE80>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data/model/wide_deep\\model.ckpt-19\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 19 into /data/model/wide_deep\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.012225711, step = 20\n",
      "INFO:tensorflow:Saving checkpoints for 25 into /data/model/wide_deep\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.00460284.\n",
      "Parsing ./data/adult.test\n",
      "dataset <BatchDataset shapes: ({age: (?,), workclass: (?,), fnlwgt: (?,), education: (?,), education_num: (?,), marital_status: (?,), occupation: (?,), relationship: (?,), race: (?,), gender: (?,), capital_gain: (?,), capital_loss: (?,), hours_per_week: (?,), native_country: (?,)}, (?,)), types: ({age: tf.int32, workclass: tf.string, fnlwgt: tf.int32, education: tf.string, education_num: tf.int32, marital_status: tf.string, occupation: tf.string, relationship: tf.string, race: tf.string, gender: tf.string, capital_gain: tf.int32, capital_loss: tf.int32, hours_per_week: tf.int32, native_country: tf.string}, tf.bool)>\n",
      "iterator <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x00000167A992E630>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-02-05:49:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data/model/wide_deep\\model.ckpt-25\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-02-05:49:55\n",
      "INFO:tensorflow:Saving dict for global step 25: accuracy = 1.0, accuracy_baseline = 1.0, auc = 0.9999999, auc_precision_recall = 0.0, average_loss = 0.0021207521, global_step = 25, label/mean = 0.0, loss = 0.01060376, precision = 0.0, prediction/mean = 0.0021000956, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25: /data/model/wide_deep\\model.ckpt-25\n",
      "Results at epoch 6\n",
      "------------------------------\n",
      "accuracy            : 1.0000\n",
      "accuracy_baseline   : 1.0000\n",
      "auc                 : 1.0000\n",
      "auc_precision_recall: 0.0000\n",
      "average_loss        : 0.0021\n",
      "global_step         : 25.0000\n",
      "label/mean          : 0.0000\n",
      "loss                : 0.0106\n",
      "precision           : 0.0000\n",
      "prediction/mean     : 0.0021\n",
      "recall              : 0.0000\n",
      "Parsing ./data/adult.data\n",
      "dataset <BatchDataset shapes: ({age: (?,), workclass: (?,), fnlwgt: (?,), education: (?,), education_num: (?,), marital_status: (?,), occupation: (?,), relationship: (?,), race: (?,), gender: (?,), capital_gain: (?,), capital_loss: (?,), hours_per_week: (?,), native_country: (?,)}, (?,)), types: ({age: tf.int32, workclass: tf.string, fnlwgt: tf.int32, education: tf.string, education_num: tf.int32, marital_status: tf.string, occupation: tf.string, relationship: tf.string, race: tf.string, gender: tf.string, capital_gain: tf.int32, capital_loss: tf.int32, hours_per_week: tf.int32, native_country: tf.string}, tf.bool)>\n",
      "iterator <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x00000167A93605F8>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data/model/wide_deep\\model.ckpt-25\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 25 into /data/model/wide_deep\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.012095762, step = 26\n",
      "INFO:tensorflow:Saving checkpoints for 31 into /data/model/wide_deep\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.004556648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./data/adult.test\n",
      "dataset <BatchDataset shapes: ({age: (?,), workclass: (?,), fnlwgt: (?,), education: (?,), education_num: (?,), marital_status: (?,), occupation: (?,), relationship: (?,), race: (?,), gender: (?,), capital_gain: (?,), capital_loss: (?,), hours_per_week: (?,), native_country: (?,)}, (?,)), types: ({age: tf.int32, workclass: tf.string, fnlwgt: tf.int32, education: tf.string, education_num: tf.int32, marital_status: tf.string, occupation: tf.string, relationship: tf.string, race: tf.string, gender: tf.string, capital_gain: tf.int32, capital_loss: tf.int32, hours_per_week: tf.int32, native_country: tf.string}, tf.bool)>\n",
      "iterator <tensorflow.python.data.ops.iterator_ops.Iterator object at 0x00000167A9C2DAC8>\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2020-04-02-05:50:00\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /data/model/wide_deep\\model.ckpt-31\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2020-04-02-05:50:01\n",
      "INFO:tensorflow:Saving dict for global step 31: accuracy = 1.0, accuracy_baseline = 1.0, auc = 0.9999999, auc_precision_recall = 0.0, average_loss = 0.0020986544, global_step = 31, label/mean = 0.0, loss = 0.010493272, precision = 0.0, prediction/mean = 0.0020784324, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 31: /data/model/wide_deep\\model.ckpt-31\n",
      "Results at epoch 9\n",
      "------------------------------\n",
      "accuracy            : 1.0000\n",
      "accuracy_baseline   : 1.0000\n",
      "auc                 : 1.0000\n",
      "auc_precision_recall: 0.0000\n",
      "average_loss        : 0.0021\n",
      "global_step         : 31.0000\n",
      "label/mean          : 0.0000\n",
      "loss                : 0.0105\n",
      "precision           : 0.0000\n",
      "prediction/mean     : 0.0021\n",
      "recall              : 0.0000\n"
     ]
    }
   ],
   "source": [
    "# ## 4）模型训练\n",
    "\n",
    "# 训练参数\n",
    "train_epochs = 3 # 10\n",
    "batch_size = 5  #5000\n",
    "train_file = './data/adult.data'\n",
    "test_file = './data/adult.test'\n",
    "\n",
    "# 6. 开始训练\n",
    "for n in range(train_epochs):\n",
    "    # 模型训练\n",
    "    model.train(input_fn=lambda: input_fn(train_file, train_epochs, True, batch_size))\n",
    "    # 模型评估\n",
    "    results = model.evaluate(input_fn=lambda: input_fn(test_file, 1, False, batch_size))\n",
    "    # 打印评估结果\n",
    "    print(\"Results at epoch {0}\".format((n+1) * train_epochs))\n",
    "    print('-'*30)\n",
    "    for key in sorted(results):\n",
    "        print(\"{0:20}: {1:.4f}\".format(key, results[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
